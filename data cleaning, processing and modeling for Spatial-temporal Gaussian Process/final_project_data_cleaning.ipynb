{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "o8uNpkgrljIz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "covid_dataset_path = '/content/drive/MyDrive/uscounties.csv'\n",
        "uscounties = pd.read_csv(covid_dataset_path)\n",
        "covid_data_filtered = pd.read_csv(\"/content/drive/MyDrive/filtered_covid_data (1).csv\")\n",
        "covid_data_filtered = covid_data_filtered.merge(\n",
        "    uscounties[['county', 'latitude', 'longitude']],\n",
        "    left_on='county_x',\n",
        "    right_on='county',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Drop the duplicate county column from the merge\n",
        "covid_data_filtered.drop(columns=['county'], inplace=True)\n",
        "covid_data_filtered.to_csv(\"/content/drive/MyDrive/filtered_covid_data_long_lat.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "g8wIDI0epU2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "# covid_data = pd.read_csv(\"/content/drive/MyDrive/filtered_covid_data_long_lat.csv\")\n",
        "california_counties = [\n",
        "    \"Alameda\", \"Alpine\", \"Amador\", \"Butte\", \"Calaveras\", \"Colusa\", \"Contra Costa\",\n",
        "    \"Del Norte\", \"El Dorado\", \"Fresno\", \"Glenn\", \"Humboldt\", \"Imperial\", \"Inyo\",\n",
        "    \"Kern\", \"Kings\", \"Lake\", \"Lassen\", \"Los Angeles\", \"Madera\", \"Marin\",\n",
        "    \"Mariposa\", \"Mendocino\", \"Merced\", \"Modoc\", \"Mono\", \"Monterey\", \"Napa\",\n",
        "    \"Nevada\", \"Orange\", \"Placer\", \"Plumas\", \"Riverside\", \"Sacramento\",\n",
        "    \"San Benito\", \"San Bernardino\", \"San Diego\", \"San Francisco\",\n",
        "    \"San Joaquin\", \"San Luis Obispo\", \"San Mateo\", \"Santa Barbara\", \"Santa Clara\",\n",
        "    \"Santa Cruz\", \"Shasta\", \"Sierra\", \"Siskiyou\", \"Solano\", \"Sonoma\",\n",
        "    \"Stanislaus\", \"Sutter\", \"Tehama\", \"Trinity\", \"Tulare\", \"Tuolumne\",\n",
        "    \"Ventura\", \"Yolo\", \"Yuba\"\n",
        "]\n",
        "\n",
        "# Ensure the 'county' column exists and is formatted correctly\n",
        "if 'county_x' not in covid_data.columns:\n",
        "    raise ValueError(\"The dataset must include a 'county' column.\")\n",
        "\n",
        "# Filter rows where the county name matches one of the California counties\n",
        "california_data = covid_data[covid_data['county_x'].isin(california_counties)]\n",
        "\n",
        "# Save the filtered dataset\n",
        "california_data.to_csv(\"/content/drive/MyDrive/california_covid_data_long_lat.csv\", index=False)\n",
        "\n",
        "print(\"Filtered dataset for California counties saved successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgo-vVFsnrj4",
        "outputId": "444d4b51-d6f5-4c86-f45a-b358ca519c67"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered dataset for California counties saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List of Texas counties\n",
        "texas_counties = [\n",
        "    \"Anderson\", \"Andrews\", \"Angelina\", \"Aransas\", \"Archer\", \"Armstrong\", \"Atascosa\",\n",
        "    \"Austin\", \"Bailey\", \"Bandera\", \"Bastrop\", \"Baylor\", \"Bee\", \"Bell\", \"Bexar\",\n",
        "    \"Blanco\", \"Borden\", \"Bosque\", \"Bowie\", \"Brazoria\", \"Brazos\", \"Brewster\", \"Briscoe\",\n",
        "    \"Brooks\", \"Brown\", \"Burleson\", \"Burnet\", \"Caldwell\", \"Calhoun\", \"Callahan\",\n",
        "    \"Cameron\", \"Camp\", \"Carson\", \"Cass\", \"Castro\", \"Chambers\", \"Cherokee\",\n",
        "    \"Childress\", \"Clay\", \"Cochran\", \"Coke\", \"Coleman\", \"Collin\", \"Collingsworth\",\n",
        "    \"Colorado\", \"Comal\", \"Comanche\", \"Concho\", \"Cooke\", \"Coryell\", \"Cottle\",\n",
        "    \"Crane\", \"Crockett\", \"Crosby\", \"Culberson\", \"Dallam\", \"Dallas\", \"Dawson\",\n",
        "    \"Deaf Smith\", \"Delta\", \"Denton\", \"DeWitt\", \"Dickens\", \"Dimmit\", \"Donley\",\n",
        "    \"Duval\", \"Eastland\", \"Ector\", \"Edwards\", \"El Paso\", \"Ellis\", \"Erath\",\n",
        "    \"Falls\", \"Fannin\", \"Fayette\", \"Fisher\", \"Floyd\", \"Foard\", \"Fort Bend\",\n",
        "    \"Franklin\", \"Freestone\", \"Frio\", \"Gaines\", \"Galveston\", \"Garza\", \"Gillespie\",\n",
        "    \"Glasscock\", \"Goliad\", \"Gonzales\", \"Gray\", \"Grayson\", \"Gregg\", \"Grimes\",\n",
        "    \"Guadalupe\", \"Hale\", \"Hall\", \"Hamilton\", \"Hansford\", \"Hardeman\", \"Hardin\",\n",
        "    \"Harris\", \"Harrison\", \"Hartley\", \"Haskell\", \"Hays\", \"Hemphill\", \"Henderson\",\n",
        "    \"Hidalgo\", \"Hill\", \"Hockley\", \"Hood\", \"Hopkins\", \"Houston\", \"Howard\",\n",
        "    \"Hudspeth\", \"Hunt\", \"Hutchinson\", \"Irion\", \"Jack\", \"Jackson\", \"Jasper\",\n",
        "    \"Jeff Davis\", \"Jefferson\", \"Jim Hogg\", \"Jim Wells\", \"Johnson\", \"Jones\",\n",
        "    \"Karnes\", \"Kaufman\", \"Kendall\", \"Kenedy\", \"Kent\", \"Kerr\", \"Kimble\",\n",
        "    \"King\", \"Kinney\", \"Kleberg\", \"Knox\", \"Lamar\", \"Lamb\", \"Lampasas\",\n",
        "    \"La Salle\", \"Lavaca\", \"Lee\", \"Leon\", \"Liberty\", \"Limestone\", \"Lipscomb\",\n",
        "    \"Live Oak\", \"Llano\", \"Loving\", \"Lubbock\", \"Lynn\", \"Madison\", \"Marion\",\n",
        "    \"Martin\", \"Mason\", \"Matagorda\", \"Maverick\", \"McCulloch\", \"McLennan\", \"McMullen\",\n",
        "    \"Medina\", \"Menard\", \"Midland\", \"Milam\", \"Mills\", \"Mitchell\", \"Montague\",\n",
        "    \"Montgomery\", \"Moore\", \"Morris\", \"Motley\", \"Nacogdoches\", \"Navarro\", \"Newton\",\n",
        "    \"Nolan\", \"Nueces\", \"Ochiltree\", \"Oldham\", \"Orange\", \"Palo Pinto\", \"Panola\",\n",
        "    \"Parker\", \"Parmer\", \"Pecos\", \"Polk\", \"Potter\", \"Presidio\", \"Rains\",\n",
        "    \"Randall\", \"Reagan\", \"Real\", \"Red River\", \"Reeves\", \"Refugio\", \"Roberts\",\n",
        "    \"Robertson\", \"Rockwall\", \"Runnels\", \"Rusk\", \"Sabine\", \"San Augustine\", \"San Jacinto\",\n",
        "    \"San Patricio\", \"San Saba\", \"Schleicher\", \"Scurry\", \"Shackelford\", \"Shelby\",\n",
        "    \"Sherman\", \"Smith\", \"Somervell\", \"Starr\", \"Stephens\", \"Sterling\", \"Stonewall\",\n",
        "    \"Sutton\", \"Swisher\", \"Tarrant\", \"Taylor\", \"Terrell\", \"Terry\", \"Throckmorton\",\n",
        "    \"Titus\", \"Tom Green\", \"Travis\", \"Trinity\", \"Tyler\", \"Upshur\", \"Upton\",\n",
        "    \"Uvalde\", \"Val Verde\", \"Van Zandt\", \"Victoria\", \"Walker\", \"Waller\",\n",
        "    \"Ward\", \"Washington\", \"Webb\", \"Wharton\", \"Wheeler\", \"Wichita\", \"Wilbarger\",\n",
        "    \"Willacy\", \"Williamson\", \"Wilson\", \"Winkler\", \"Wise\", \"Wood\", \"Yoakum\",\n",
        "    \"Young\", \"Zapata\", \"Zavala\"\n",
        "]\n",
        "\n",
        "# Filter rows where the county name matches one of the Texas counties\n",
        "texas_data = covid_data[covid_data['county_x'].isin(texas_counties)]\n",
        "\n",
        "# Save the filtered dataset\n",
        "texas_data.to_csv(\"/content/drive/MyDrive/texas_covid_data.csv\", index=False)\n",
        "\n",
        "print(\"Filtered dataset for Texas counties saved successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW-aUqVKFUIL",
        "outputId": "16e54971-b31a-430f-92a8-7012c5d3cbca"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered dataset for Texas counties saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List of New York counties\n",
        "new_york_counties = [\n",
        "    \"Albany\", \"Allegany\", \"Bronx\", \"Broome\", \"Cattaraugus\", \"Cayuga\", \"Chautauqua\",\n",
        "    \"Chemung\", \"Chenango\", \"Clinton\", \"Columbia\", \"Cortland\", \"Delaware\", \"Dutchess\",\n",
        "    \"Erie\", \"Essex\", \"Franklin\", \"Fulton\", \"Genesee\", \"Greene\", \"Hamilton\", \"Herkimer\",\n",
        "    \"Jefferson\", \"Kings\", \"Lewis\", \"Livingston\", \"Madison\", \"Monroe\", \"Montgomery\",\n",
        "    \"Nassau\", \"New York\", \"Niagara\", \"Oneida\", \"Onondaga\", \"Ontario\", \"Orange\",\n",
        "    \"Orleans\", \"Oswego\", \"Otsego\", \"Putnam\", \"Queens\", \"Rensselaer\", \"Richmond\",\n",
        "    \"Rockland\", \"Saratoga\", \"Schenectady\", \"Schoharie\", \"Schuyler\", \"Seneca\", \"St. Lawrence\",\n",
        "    \"Steuben\", \"Suffolk\", \"Sullivan\", \"Tioga\", \"Tompkins\", \"Ulster\", \"Warren\",\n",
        "    \"Washington\", \"Wayne\", \"Westchester\", \"Wyoming\", \"Yates\"\n",
        "]\n",
        "new_york_data = covid_data[covid_data['county_x'].isin(new_york_counties)]\n",
        "\n",
        "# Save the filtered dataset\n",
        "new_york_data.to_csv(\"/content/drive/MyDrive/new_york_data_long_lat.csv\", index=False)\n",
        "\n",
        "print(\"Filtered dataset for New York counties saved successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTL_ffOsFUs-",
        "outputId": "619988a4-ce0e-4342-cd95-9d6e038d36a7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered dataset for New York counties saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import faiss\n",
        "\n",
        "covid_data = pd.read_csv(\"/content/drive/MyDrive/california_covid_data_long_lat.csv\")\n",
        "# Ensure the required columns exist\n",
        "if not all(col in covid_data.columns for col in ['latitude', 'longitude', 'population']):\n",
        "    raise ValueError(\"Dataset must include 'latitude', 'longitude', and 'population' columns.\")\n",
        "\n",
        "# Prepare data for FAISS (convert coordinates to float32 and radians)\n",
        "coordinates = covid_data[['latitude', 'longitude']].to_numpy(dtype=np.float32)\n",
        "coordinates_radians = np.radians(coordinates)\n",
        "\n",
        "# Build FAISS index\n",
        "index = faiss.IndexFlatL2(coordinates_radians.shape[1])  # L2 norm for Euclidean space\n",
        "index.add(coordinates_radians)  # Add data to the index\n",
        "\n",
        "# Query for the 2 nearest neighbors\n",
        "distances, indices = index.search(coordinates_radians, 3)  # 3 nearest neighbors\n",
        "\n",
        "# Compute the closest 2 counties' population\n",
        "closest_populations = [\n",
        "    covid_data.iloc[neighbors[1:3]]['population'].sum()  # Skip itself (index 0)\n",
        "    for neighbors in indices\n",
        "]\n",
        "\n",
        "# Add the results as a new column\n",
        "covid_data['closest_2_county_population'] = closest_populations\n",
        "\n",
        "# Save the updated dataset\n",
        "covid_data.to_csv(\"/content/drive/MyDrive/california_covid_data_with_closest_4_population.csv\", index=False)\n",
        "\n",
        "print(\"New column 'closest_2_county_population' added successfully using FAISS.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52y0UjS0EOn0",
        "outputId": "7973110d-b2f3-4afd-e2d2-aeffb0a8d728"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New column 'closest_4_county_population' added successfully using FAISS.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/california_covid_data_with_closest_4_population.csv\")  # Replace with the actual file path\n",
        "\n",
        "# Ensure the dataset has the required columns\n",
        "if not all(col in data.columns for col in ['county_x', 'date']):\n",
        "    raise ValueError(\"Dataset must include 'county_x' and 'date' columns.\")\n",
        "\n",
        "# Convert the 'date' column to datetime format\n",
        "data['date'] = pd.to_datetime(data['date'])\n",
        "\n",
        "# Select the first row for each county on each date\n",
        "first_rows = data.groupby(['county_x', 'date']).first().reset_index()\n",
        "\n",
        "# Save or display the result\n",
        "first_rows.to_csv(\"/content/drive/MyDrive/california_covid_data_with_closest_2_population.csv\", index=False)  # Replace with your desired save path\n",
        "print(first_rows)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGQ6ikaBYXvj",
        "outputId": "e604685e-e334-4e00-cc2b-5b420f248001"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      county_x       date  Unnamed: 0    fips  cases  deaths  population  \\\n",
            "0      Alameda 2020-03-01     9437650  6001.0      1     0.0     1680466   \n",
            "1      Alameda 2020-03-02     9437651  6001.0      1     0.0     1680466   \n",
            "2      Alameda 2020-03-03     9437652  6001.0      2     0.0     1680466   \n",
            "3      Alameda 2020-03-04     9437653  6001.0      2     0.0     1680466   \n",
            "4      Alameda 2020-03-05     9437654  6001.0      2     0.0     1680466   \n",
            "...        ...        ...         ...     ...    ...     ...         ...   \n",
            "45697     Yuba 2022-05-09     9670312  6115.0  17845   122.0       84353   \n",
            "45698     Yuba 2022-05-10     9670313  6115.0  17845   122.0       84353   \n",
            "45699     Yuba 2022-05-11     9670314  6115.0  17845   122.0       84353   \n",
            "45700     Yuba 2022-05-12     9670315  6115.0  17944   122.0       84353   \n",
            "45701     Yuba 2022-05-13     9670316  6115.0  17944   122.0       84353   \n",
            "\n",
            "       days_since_zero  cases_last_week  deaths_last_week  cases_per_100k  \\\n",
            "0                   40              0.0               0.0        0.000000   \n",
            "1                   41              0.0               0.0        0.000000   \n",
            "2                   42              0.0               0.0        0.000000   \n",
            "3                   43              0.0               0.0        0.000000   \n",
            "4                   44              0.0               0.0        0.000000   \n",
            "...                ...              ...               ...             ...   \n",
            "45697              839             52.0               1.0       63.643596   \n",
            "45698              840             52.0               0.0       63.643596   \n",
            "45699              841              0.0               0.0        0.000000   \n",
            "45700              842             99.0               0.0      121.167615   \n",
            "45701              843             99.0               0.0      121.167615   \n",
            "\n",
            "       deaths_per_100k risk_level  neighbor_population_sum    year  latitude  \\\n",
            "0             0.000000        Low                4684765.0  2020.0   37.6469   \n",
            "1             0.000000        Low                4684765.0  2020.0   37.6469   \n",
            "2             0.000000        Low                4684765.0  2020.0   37.6469   \n",
            "3             0.000000        Low                4684765.0  2020.0   37.6469   \n",
            "4             0.000000        Low                4684765.0  2020.0   37.6469   \n",
            "...                ...        ...                      ...     ...       ...   \n",
            "45697         1.223915     Medium                 516606.0  2022.0   39.2690   \n",
            "45698         0.000000     Medium                 516606.0  2022.0   39.2690   \n",
            "45699         0.000000        Low                 516606.0  2022.0   39.2690   \n",
            "45700         0.000000       High                 516606.0  2022.0   39.2690   \n",
            "45701         0.000000       High                 516606.0  2022.0   39.2690   \n",
            "\n",
            "       longitude  closest_4_county_population  \n",
            "0      -121.8887                      3360932  \n",
            "1      -121.8887                      3360932  \n",
            "2      -121.8887                      3360932  \n",
            "3      -121.8887                      3360932  \n",
            "4      -121.8887                      3360932  \n",
            "...          ...                          ...  \n",
            "45697  -121.3513                       163916  \n",
            "45698  -121.3513                       163916  \n",
            "45699  -121.3513                       163916  \n",
            "45700  -121.3513                       163916  \n",
            "45701  -121.3513                       163916  \n",
            "\n",
            "[45702 rows x 18 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Drop the specified columns\n",
        "columns_to_drop = ['fips', 'cases_last_week', 'deaths_last_week', 'cases_per_100k',\n",
        "                   'deaths_per_100k', 'risk_level', 'neighbor_population_sum']\n",
        "covid_data_california = pd.read_csv(\"/content/drive/MyDrive/california_covid_data_with_closest_2_population.csv\")\n",
        "covid_data_california = covid_data_california.drop(columns=columns_to_drop)\n",
        "# Rename the column\n",
        "covid_data_california = covid_data_california.rename(columns={'closest_4_county_population': 'closest_2_county_population'})\n",
        "# Load the reference dataset containing county areas\n",
        "county_area_data = pd.read_csv(\"/content/drive/MyDrive/California_Area.csv\")  # Update with your file path\n",
        "# Ensure both datasets have a 'county' column and match formatting\n",
        "covid_data_california = covid_data_california.rename(columns={'county_x': 'county'})\n",
        "county_area_data['county'] = county_area_data['county'].str.replace(' County', '', regex=False)\n",
        "# Merge the area data into the California dataset\n",
        "covid_data_california = covid_data_california.merge(county_area_data, on='county', how='left')\n",
        "# Save the updated dataset\n",
        "updated_file_path = \"/content/drive/MyDrive/updated_california_data_with_area.csv\"  # Update with your desired save path\n",
        "covid_data_california.to_csv(updated_file_path, index=False)\n",
        "\n",
        "print(\"Updated dataset with area column saved successfully.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsvsWN1pIDZm",
        "outputId": "e54a9265-8a64-4e9a-a704-3891264464b4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated dataset with area column saved successfully.\n",
            "    county        date  Unnamed: 0  cases  deaths  population  \\\n",
            "0  Alameda  2020-03-01     9437650      1     0.0     1680466   \n",
            "1  Alameda  2020-03-02     9437651      1     0.0     1680466   \n",
            "2  Alameda  2020-03-03     9437652      2     0.0     1680466   \n",
            "3  Alameda  2020-03-04     9437653      2     0.0     1680466   \n",
            "4  Alameda  2020-03-05     9437654      2     0.0     1680466   \n",
            "\n",
            "   days_since_zero    year  latitude  longitude  closest_2_county_population  \\\n",
            "0               40  2020.0   37.6469  -121.8887                      3360932   \n",
            "1               41  2020.0   37.6469  -121.8887                      3360932   \n",
            "2               42  2020.0   37.6469  -121.8887                      3360932   \n",
            "3               43  2020.0   37.6469  -121.8887                      3360932   \n",
            "4               44  2020.0   37.6469  -121.8887                      3360932   \n",
            "\n",
            "   AREA_SqMi  \n",
            "0   820.7918  \n",
            "1   820.7918  \n",
            "2   820.7918  \n",
            "3   820.7918  \n",
            "4   820.7918  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/updated_california_data_with_area.csv\")\n",
        "data['population_density'] = data['population'] / data['AREA_SqMi']\n",
        "\n",
        "# Save the updated dataset\n",
        "data.to_csv(\"/content/drive/MyDrive/updated_dataset_with_density.csv\", index=False)  # Replace with your desired save path\n",
        "\n",
        "print(\"Population density added successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0mnh-BLZ_ty",
        "outputId": "ece22b9d-69ca-488f-ce4e-c6c55a9e80f2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Population density added successfully.\n",
            "    county        date  Unnamed: 0  cases  deaths  population  \\\n",
            "0  Alameda  2020-03-01     9437650      1     0.0     1680466   \n",
            "1  Alameda  2020-03-02     9437651      1     0.0     1680466   \n",
            "2  Alameda  2020-03-03     9437652      2     0.0     1680466   \n",
            "3  Alameda  2020-03-04     9437653      2     0.0     1680466   \n",
            "4  Alameda  2020-03-05     9437654      2     0.0     1680466   \n",
            "\n",
            "   days_since_zero    year  latitude  longitude  closest_2_county_population  \\\n",
            "0               40  2020.0   37.6469  -121.8887                      3360932   \n",
            "1               41  2020.0   37.6469  -121.8887                      3360932   \n",
            "2               42  2020.0   37.6469  -121.8887                      3360932   \n",
            "3               43  2020.0   37.6469  -121.8887                      3360932   \n",
            "4               44  2020.0   37.6469  -121.8887                      3360932   \n",
            "\n",
            "   AREA_SqMi  population_density  \n",
            "0   820.7918         2047.371818  \n",
            "1   820.7918         2047.371818  \n",
            "2   820.7918         2047.371818  \n",
            "3   820.7918         2047.371818  \n",
            "4   820.7918         2047.371818  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/updated_dataset_with_density.csv\")  # Replace with the actual file path\n",
        "\n",
        "# Ensure the required columns are present\n",
        "if not all(col in data.columns for col in ['cases', 'population', 'county', 'date']):\n",
        "    raise ValueError(\"Dataset must include 'cases', 'population', 'county', and 'date' columns.\")\n",
        "\n",
        "# Calculate the daily change in cases\n",
        "data['daily_change'] = data.groupby('county')['cases'].diff()\n",
        "\n",
        "# Calculate the daily change per 100,000 people\n",
        "data['daily_change_per_100k'] = (data['daily_change'] / data['population']) * 100000\n",
        "\n",
        "# Fill NaN values (e.g., for the first day of each county) with 0\n",
        "data['daily_change_per_100k'] = data['daily_change_per_100k'].fillna(0)\n",
        "\n",
        "# Save the updated dataset\n",
        "data.to_csv(\"/content/drive/MyDrive/updated_dataset_with_daily_change.csv\", index=False)  # Replace with your desired save path\n",
        "\n",
        "print(\"Daily change per 100,000 people added successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q673Vn5CbXGk",
        "outputId": "ef65d506-6507-459c-bbd2-10210bbe8c19"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Daily change per 100,000 people added successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the datasets for further processing\n",
        "import pandas as pd\n",
        "\n",
        "# Paths to the datasets\n",
        "updated_data_path = '/content/drive/MyDrive/updated_dataset_with_daily_change.csv'\n",
        "mobility_2020_path = '/content/drive/MyDrive/2020_US_Region_Mobility_Report.csv'\n",
        "mobility_2021_path = '/content/drive/MyDrive/2021_US_Region_Mobility_Report.csv'\n",
        "mobility_2022_path = '/content/drive/MyDrive/2022_US_Region_Mobility_Report.csv'\n",
        "\n",
        "# Load the datasets into DataFrames\n",
        "updated_data = pd.read_csv(updated_data_path)\n",
        "mobility_2020 = pd.read_csv(mobility_2020_path)\n",
        "mobility_2021 = pd.read_csv(mobility_2021_path)\n",
        "mobility_2022 = pd.read_csv(mobility_2022_path)\n",
        "\n",
        "# Combine mobility datasets\n",
        "mobility_data = pd.concat([mobility_2020, mobility_2021, mobility_2022], ignore_index=True)\n",
        "\n",
        "# Drop rows where the 'county' column is empty\n",
        "mobility_data = mobility_data.dropna(subset=['county'])\n",
        "mobility_data['county'] = mobility_data['county'].str.replace(' County', '', regex=False)\n",
        "# Rename columns for consistency\n",
        "mobility_data = mobility_data.rename(columns={\n",
        "    'date': 'mobility_date',\n",
        "    'retail_and_recreation_percent_change_from_baseline': 'retail',\n",
        "    'grocery_and_pharmacy_percent_change_from_baseline': 'grocery',\n",
        "    'parks_percent_change_from_baseline': 'parks',\n",
        "    'transit_stations_percent_change_from_baseline': 'transit',\n",
        "    'workplaces_percent_change_from_baseline': 'workplace',\n",
        "    'residential_percent_change_from_baseline': 'residential'\n",
        "})\n",
        "# Calculate the mobility index as the sum of percentage changes in 6 categories\n",
        "mobility_data['mobility_index'] = mobility_data[['retail', 'grocery', 'parks', 'transit', 'workplace', 'residential']].sum(axis=1)\n",
        "\n",
        "# Keep only necessary columns\n",
        "mobility_data = mobility_data[['county', 'mobility_date', 'mobility_index']]\n",
        "\n",
        "# Convert date columns to datetime for merging\n",
        "updated_data['date'] = pd.to_datetime(updated_data['date'])\n",
        "mobility_data['mobility_date'] = pd.to_datetime(mobility_data['mobility_date'])\n",
        "\n",
        "# Merge the updated dataset with mobility data\n",
        "merged_data = updated_data.merge(\n",
        "    mobility_data,\n",
        "    how='left',\n",
        "    left_on=['county', 'date'],\n",
        "    right_on=['county', 'mobility_date']\n",
        ")\n",
        "\n",
        "# Drop the 'mobility_date' column after merging\n",
        "merged_data = merged_data.drop(columns=['mobility_date'])\n",
        "\n",
        "# Save the updated dataset with the mobility index\n",
        "output_path = '/content/drive/MyDrive/updated_dataset_with_mobility_index.csv'\n",
        "merged_data.to_csv(output_path, index=False)\n",
        "\n",
        "print(\"Updated dataset with mobility index saved successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuF2ee8Dds0o",
        "outputId": "39334eb5-81de-4deb-8d75-b50fa0d979ac"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated dataset with mobility index saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Reload the dataset with healthcare facility bed information\n",
        "file_path = '/content/drive/MyDrive/healthcare_facility_beds.csv'  # Update this path if necessary\n",
        "healthcare_data = pd.read_csv(file_path)\n",
        "if 'COUNTY_NAME' in healthcare_data.columns:\n",
        "    healthcare_data.rename(columns={'COUNTY_NAME': 'county'}, inplace=True)\n",
        "    healthcare_data['county'] = healthcare_data['county'].str.title()  # Convert to title case (capitalize first letter of each word)\n",
        "if \"BED_CAPACITY\" in healthcare_data.columns:\n",
        "    healthcare_data.rename(columns={'BED_CAPACITY': 'beds'}, inplace=True)\n",
        "# Group the data by 'county' and calculate the total facility beds for each county\n",
        "if 'county' in healthcare_data.columns and 'beds' in healthcare_data.columns:\n",
        "    county_beds_data = healthcare_data.groupby('county', as_index=False)['beds'].sum()\n",
        "    county_beds_data.rename(columns={'beds': 'total_facility_bed'}, inplace=True)\n",
        "\n",
        "    # Save the new dataset with county and total facility bed data\n",
        "    output_file_path = '/content/drive/MyDrive/healthcare_facility_beds.csv'\n",
        "    county_beds_data.to_csv(output_file_path, index=False)\n",
        "\n",
        "    print(f\"New dataset with 'county' and 'total_facility_bed' has been saved to: {output_file_path}\")\n",
        "else:\n",
        "    print(\"The required columns 'county' and 'beds' are not present in the uploaded dataset.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCQcbWvU_10T",
        "outputId": "301f3ab2-23f0-40d4-d3c5-7cd85fe21ac6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New dataset with 'county' and 'total_facility_bed' has been saved to: /content/drive/MyDrive/healthcare_facility_beds.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the datasets\n",
        "# Assuming 'county_total_facility_beds.csv' contains 'county' and 'total_facility_bed'\n",
        "facility_bed_data = pd.read_csv('/content/drive/MyDrive/healthcare_facility_beds.csv')\n",
        "updated_dataset = pd.read_csv('/content/drive/MyDrive/updated_dataset_with_mobility_index.csv')\n",
        "\n",
        "# Merge the two datasets on the 'county' column\n",
        "merged_dataset = updated_dataset.merge(facility_bed_data, how='left', on='county')\n",
        "\n",
        "# Save the merged dataset to a new CSV file\n",
        "merged_file_path = '/content/drive/MyDrive/updated_dataset_with_facility_beds.csv'\n",
        "merged_dataset.to_csv(merged_file_path, index=False)\n",
        "\n",
        "print(f\"The merged dataset with 'total_facility_bed' has been saved to: {merged_file_path}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BoQ85H7YllC",
        "outputId": "2f6df0b7-8514-4b22-e5da-398a6fc00c49"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The merged dataset with 'total_facility_bed' has been saved to: /content/drive/MyDrive/updated_dataset_with_facility_beds.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/drive/MyDrive/covid19vaccinesbycounty.csv'\n",
        "vaccine_data = pd.read_csv(file_path)\n",
        "if \"administered_date\" in vaccine_data.columns:\n",
        "    vaccine_data.rename(columns={'administered_date': 'date'}, inplace=True)\n",
        "# Check for required columns\n",
        "if 'county' in vaccine_data.columns and 'date' in vaccine_data.columns and 'cumulative_total_doses' in vaccine_data.columns:\n",
        "    # Convert 'date' column to datetime format for sorting and calculations\n",
        "    vaccine_data['date'] = pd.to_datetime(vaccine_data['date'])\n",
        "\n",
        "    # Sort the data by county and date to prepare for difference calculation\n",
        "    vaccine_data.sort_values(by=['county', 'date'], inplace=True)\n",
        "\n",
        "    # Calculate the difference in cumulative_total_doses for each county\n",
        "    vaccine_data['change_in_doses'] = vaccine_data.groupby('county')['cumulative_total_doses'].diff()\n",
        "\n",
        "    # Save the updated dataset\n",
        "    output_file_path = '/content/drive/MyDrive/covid19vaccinesbycounty.csv'\n",
        "    vaccine_data.to_csv(output_file_path, index=False)\n",
        "\n",
        "    print(f\"Dataset with 'change_in_doses' column added has been saved to: {output_file_path}\")\n",
        "else:\n",
        "    print(\"The dataset must contain 'county', 'date', and 'cumulative_total_doses' columns.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfA_oL3TGOFp",
        "outputId": "f410524b-cab7-4655-ab16-4a32353311dd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset with 'change_in_doses' column added has been saved to: /content/drive/MyDrive/covid19vaccinesbycounty.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the datasets\n",
        "facility_beds_file = '/content/drive/MyDrive/updated_dataset_with_facility_beds.csv'\n",
        "vaccine_data_file = '/content/drive/MyDrive/covid19vaccinesbycounty.csv'\n",
        "\n",
        "# Load the data\n",
        "facility_beds_data = pd.read_csv(facility_beds_file)\n",
        "vaccine_data = pd.read_csv(vaccine_data_file)\n",
        "\n",
        "if 'date' in facility_beds_data.columns and 'date' in vaccine_data.columns:\n",
        "    facility_beds_data['date'] = pd.to_datetime(facility_beds_data['date'])\n",
        "    vaccine_data['date'] = pd.to_datetime(vaccine_data['date'])\n",
        "else:\n",
        "    print(\"The 'date' column is missing in one of the datasets.\")\n",
        "\n",
        "# Merge the datasets on 'county' and 'date'\n",
        "merged_data = facility_beds_data.merge(\n",
        "    vaccine_data[['county', 'date', 'change_in_doses']],\n",
        "    how='left',\n",
        "    on=['county', 'date']\n",
        ")\n",
        "\n",
        "# Save the updated dataset\n",
        "output_file_path = '/content/drive/MyDrive/updated_dataset_with_vaccine_change.csv'\n",
        "merged_data.to_csv(output_file_path, index=False)\n",
        "\n",
        "print(f\"Dataset with 'vaccine_equity_metric' added has been saved to: {output_file_path}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEsTme86Fehl",
        "outputId": "d67fd68f-7327-4928-8ac3-f6e5dd430cf1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset with 'vaccine_equity_metric' added has been saved to: /content/drive/MyDrive/updated_dataset_with_vaccine_change.csv\n"
          ]
        }
      ]
    }
  ]
}